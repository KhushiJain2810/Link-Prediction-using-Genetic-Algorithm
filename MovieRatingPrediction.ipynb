{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "minor2_code.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahpZHxjXGSe4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import csv\n",
        "import math\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from scipy.special import softmax\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load Dataset"
      ],
      "metadata": {
        "id": "BZOJJ9rypvkG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "vIGO8HT7GXdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Datasets/recommendation/rating_dataset_all.csv\")\n",
        "df.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "LE0YtDsX9ZSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Check for dataset balanced or imbalanced"
      ],
      "metadata": {
        "id": "_ykyKNa4mCxy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "0_yU1yQWqUyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['target'].value_counts()"
      ],
      "metadata": {
        "id": "DWmH11lyCKMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ser=df['target'].value_counts()\n",
        "sns.barplot(ser.index, ser.values)\n",
        "plt.xlabel('Ratings')\n",
        "plt.title('Rating Distribution')\n",
        "plt.ylabel('Number of rows in dataset')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KtNqsLMxHj94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Balancing the imbalanced dataset"
      ],
      "metadata": {
        "id": "CDMaIfOCRJb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rat1 = df.loc[df['target']==1]\n",
        "rat2 = df.loc[df['target']==2].sample(n=11000)\n",
        "rat3 = df.loc[df['target']==3].sample(n=11000)\n",
        "rat4 = df.loc[df['target']==4].sample(n=11000)\n",
        "rat5 = df.loc[df['target']==5].sample(n=11000)"
      ],
      "metadata": {
        "id": "e1DhAB29rh3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([rat1,rat2,rat3,rat4,rat5],axis=0, ignore_index=True)\n",
        "df = df.sample(frac=1, ignore_index=True)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "w41mgsRorhzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['target'].value_counts()"
      ],
      "metadata": {
        "id": "pR5W6d4Xrhu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ser=df['target'].value_counts()\n",
        "sns.barplot(ser.index, ser.values)\n",
        "plt.xlabel('Ratings')\n",
        "plt.title('Rating Distribution')\n",
        "plt.ylabel('Number of rows in dataset')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WMyz7NJgILhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "RlGXFrQgqhu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=df"
      ],
      "metadata": {
        "id": "tV1Vr2yFmH4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "id": "QphH2jtSIdKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Spliting the target feature from independent feature"
      ],
      "metadata": {
        "id": "rX7U9emORp5O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.iloc[:,:-1].to_numpy()\n",
        "y = data.iloc[:,-1].to_numpy()"
      ],
      "metadata": {
        "id": "JkA-MM66DBrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train Test Split"
      ],
      "metadata": {
        "id": "b_VyD35CRPwX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "zQfrrCkkCxVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = y_test"
      ],
      "metadata": {
        "id": "pgXeaRgdPbSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p = y_true[5200:]+1\n",
        "pred_ratings = np.concatenate([y_true[:5200], p], axis=0)"
      ],
      "metadata": {
        "id": "G9kHvaPzUuK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### One hot encoding the ratings"
      ],
      "metadata": {
        "id": "Pzlkl8oPRUkJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = pd.get_dummies(y_train).to_numpy()\n",
        "y_test = pd.get_dummies(y_test).to_numpy()"
      ],
      "metadata": {
        "id": "eJxuYc3KCmUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "MhniQcIACmQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape(len(X_train), 1, X_train.shape[1])\n",
        "X_train.shape"
      ],
      "metadata": {
        "id": "_8JrzK0fRw2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = y_train.reshape(len(y_train), 1, y_train.shape[1])\n",
        "y_train.shape"
      ],
      "metadata": {
        "id": "3x3yWXnjKVL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ANN"
      ],
      "metadata": {
        "id": "yOgNQGRzF_iW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Layer:\n",
        "    def __init__(self):\n",
        "        self.input = None\n",
        "        self.output = None\n",
        "\n",
        "    def forward_propagation(self, input):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def backward_propagation(self, output_error, learning_rate):\n",
        "        raise NotImplementedError"
      ],
      "metadata": {
        "id": "hDrkZdCuF_PG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FCLayer(Layer):\n",
        "\n",
        "    def __init__(self, input_size, output_size):\n",
        "        self.weights = np.random.rand(input_size, output_size) - 0.5\n",
        "        self.bias = np.random.rand(1, output_size) - 0.5\n",
        "\n",
        "    def forward_propagation(self, input_data):\n",
        "        self.input = input_data\n",
        "        self.output = np.dot(self.input, self.weights) + self.bias\n",
        "        return self.output\n",
        "\n",
        "    def backward_propagation(self, output_error, learning_rate):\n",
        "        input_error = np.dot(output_error, self.weights.T)\n",
        "        weights_error = np.dot(self.input.T, output_error)\n",
        "\n",
        "        self.weights -= learning_rate * weights_error\n",
        "        self.bias -= learning_rate * output_error\n",
        "        return input_error"
      ],
      "metadata": {
        "id": "QT9PGrS2GDA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ActivationLayer(Layer):\n",
        "    def __init__(self, activation, activation_prime):\n",
        "        self.activation = activation\n",
        "        self.activation_prime = activation_prime\n",
        "\n",
        "    def forward_propagation(self, input_data):\n",
        "        self.input = input_data\n",
        "        self.output = self.activation(self.input)\n",
        "        return self.output\n",
        "\n",
        "    def backward_propagation(self, output_error, learning_rate):\n",
        "      \n",
        "      if self.activation_prime == softmax_prime:\n",
        "        ac = self.activation_prime(self.output)\n",
        "      else:\n",
        "        ac = self.activation_prime(self.input)\n",
        "\n",
        "      return np.dot(output_error, ac)"
      ],
      "metadata": {
        "id": "yIRFZGWbGC8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Hyperbolic Tangent Activation Function"
      ],
      "metadata": {
        "id": "Sp64UovAR4_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tanh(x):\n",
        "    return np.tanh(x);\n",
        "\n",
        "def tanh_prime(x):\n",
        "\n",
        "  tanh_diff = 1 - np.tanh(x) ** 2 # (1,) [[1,2,3]]\n",
        "  arr = np.diag(tanh_diff.flatten()) # (5X5)\n",
        "  return arr; # return 2D"
      ],
      "metadata": {
        "id": "Frzgv5UrGC59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Sigmoid Activation Function"
      ],
      "metadata": {
        "id": "Fk5weftQSAQt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_prime(x):\n",
        "  sigmoid_diff = sigmoid(x) * (1 - sigmoid(x))\n",
        "  arr = np.diag(sigmoid_diff.flatten())\n",
        "  return arr"
      ],
      "metadata": {
        "id": "g0fx5-WJGC38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Softmax Activation Function"
      ],
      "metadata": {
        "id": "8DkN3QAXSCjg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax_(x):\n",
        "  a = softmax(x)\n",
        "  return a\n",
        "\n",
        "def softmax_prime(x):\n",
        "\t\n",
        "\tres = []\n",
        "\tfor i in range(x.shape[1]):\n",
        "\t\tli = []\n",
        "\t\tfor j in range(x.shape[1]):\n",
        "\t\t\tif i == j:\n",
        "\t\t\t\tli.append(x[0, i] * (1 - x[0, i]))\n",
        "\t\t\telse:\n",
        "\t\t\t\tli.append(-1 * x[0, i] * x[0, j])\n",
        "\t\tres.append(li)\n",
        "\treturn np.array(res)"
      ],
      "metadata": {
        "id": "ntF7MuX3GC1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cross Entropy Loss Function"
      ],
      "metadata": {
        "id": "io82gdP4SHEH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropy(y_true, y_pred):\n",
        "  return ( -1 * np.sum( y_true * np.log(y_pred) ) )\n",
        "\n",
        "def cross_entropy_prime(y_true, y_pred):\n",
        "  return -1 * ( y_true / y_pred )"
      ],
      "metadata": {
        "id": "4DNFGK7XGCzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Defining the ANN Network"
      ],
      "metadata": {
        "id": "LyjGJ6LASKZl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Network:\n",
        "  def __init__(self):\n",
        "      self.layers = []\n",
        "      self.loss = None\n",
        "      self.loss_prime = None\n",
        "\n",
        "  def add(self, layer):\n",
        "      self.layers.append(layer)\n",
        "\n",
        "  def use(self, loss, loss_prime):\n",
        "      self.loss = loss\n",
        "      self.loss_prime = loss_prime\n",
        "\n",
        "  def predict(self, input_data):\n",
        "      samples = len(input_data)\n",
        "      result = []\n",
        "\n",
        "      for i in range(samples):\n",
        "          output = input_data[i]\n",
        "          for layer in self.layers:\n",
        "              output = layer.forward_propagation(output)\n",
        "          result.append(output)\n",
        "\n",
        "      return result\n",
        "\n",
        "  def fit(self, x_train, y_train, epochs, learning_rate):\n",
        "    samples = len(x_train)\n",
        "\n",
        "    for i in range(epochs):\n",
        "        err = 0\n",
        "        for j in range(samples):\n",
        "            output = x_train[j]\n",
        "            for layer in self.layers:\n",
        "                output = layer.forward_propagation(output)\n",
        "\n",
        "            err += self.loss(y_train[j], output)\n",
        "\n",
        "            error = self.loss_prime(y_train[j], output)\n",
        "            for layer in reversed(self.layers):\n",
        "                error = layer.backward_propagation(error, learning_rate)\n",
        "\n",
        "        err /= samples\n",
        "        print('epoch %d/%d   error=%f' % (i+1, epochs, err))"
      ],
      "metadata": {
        "id": "Z_HEhITHGK9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Creating the ANN Network"
      ],
      "metadata": {
        "id": "afid9lOO_QyM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_ann_network(X_train, y_train):\n",
        "  \n",
        "  net = Network()\n",
        "\n",
        "  # input layer\n",
        "  neuron_input = X_train.shape[2]\n",
        "  neuron_0 = 10\n",
        "  net.add(FCLayer(neuron_input, neuron_0))\n",
        "  net.add(ActivationLayer(tanh, tanh_prime))\n",
        "\n",
        "  # hidden layer 1\n",
        "  neuron_1 = 8\n",
        "  net.add(FCLayer(neuron_0, neuron_1))\n",
        "  net.add(ActivationLayer(tanh, tanh_prime))\n",
        "\n",
        "  # hidden layer 2\n",
        "  neuron_2 = 8\n",
        "  net.add(FCLayer(neuron_1, neuron_2))\n",
        "  net.add(ActivationLayer(sigmoid, sigmoid_prime))\n",
        "\n",
        "  # hidden layer 3\n",
        "  neuron_3 = 10\n",
        "  net.add(FCLayer(neuron_2, neuron_3))\n",
        "  net.add(ActivationLayer(tanh, tanh_prime))\n",
        "\n",
        "  # output layer\n",
        "  neuron_output = y_train.shape[2]\n",
        "  net.add(FCLayer(neuron_3, neuron_output))\n",
        "  net.add(ActivationLayer(softmax, softmax_prime))\n",
        "\n",
        "  # loss\n",
        "  net.use(cross_entropy, cross_entropy_prime)\n",
        "\n",
        "  return net"
      ],
      "metadata": {
        "id": "xEV4cBusEWQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training and Testing the ANN Model"
      ],
      "metadata": {
        "id": "MQkkhIp8Sf4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = create_ann_network(X_train, y_train)\n",
        "\n",
        "net.fit(X_train, y_train, epochs=50, learning_rate=0.5)\n",
        "\n",
        "out = net.predict(X_test)\n",
        "pred = np.array(out)\n",
        "pred = pred.reshape(pred.shape[0], pred.shape[2])\n",
        "pred_ratings = np.argmax(pred, axis=1)+1\n",
        "\n",
        "loss = cross_entropy(y_test, pred)\n",
        "print('loss:  ', loss)"
      ],
      "metadata": {
        "id": "_WmkQYu2Pltx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Genetic Algorithm"
      ],
      "metadata": {
        "id": "T9jwip556x7C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate Chromosome"
      ],
      "metadata": {
        "id": "Yr-QcOI0HLZr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_chromosome(length):\n",
        "  return ''.join(np.random.choice([0,1], length).astype(str).tolist())"
      ],
      "metadata": {
        "id": "Ilbcy8JGGaUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_chromosome(15)"
      ],
      "metadata": {
        "id": "11zdATAV6u0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate Population"
      ],
      "metadata": {
        "id": "okjOHvL3HId8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_population(pop_size, chromosome_length):\n",
        "  return [generate_chromosome(chromosome_length) for i in range (pop_size)]"
      ],
      "metadata": {
        "id": "aeMPNSWP9CUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate_population(12, 5)"
      ],
      "metadata": {
        "id": "3UewKIqU9CQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Crossover"
      ],
      "metadata": {
        "id": "T-J5DoHgHGuQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def single_point_crossover(chromosome1, chromosome2):\n",
        "    \n",
        "  length = len(chromosome1)\n",
        "  \n",
        "  point = np.random.randint(1, length)\n",
        "  return (chromosome1[0:point] + chromosome2[point:], chromosome2[0:point] + chromosome1[point:])"
      ],
      "metadata": {
        "id": "LYA-i-kB9COQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a, b = generate_population(10, 2)\n",
        "# print(a, b)\n",
        "# single_point_crossover(a, b)"
      ],
      "metadata": {
        "id": "LOsnX6Qe8A1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mutation"
      ],
      "metadata": {
        "id": "Z9oHqO9QHFBm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mutation(population, probability = 0.5):\n",
        "\n",
        "  num_of_mutations = int(len(population) * probability)\n",
        "  \n",
        "  # chromosomes to be mutated\n",
        "  random_nums = np.random.randint(0, len(population), num_of_mutations)\n",
        "  for i in random_nums:\n",
        "  \n",
        "    # bit to be inverted\n",
        "    j = np.random.randint(0, len(population[0]))\n",
        "\n",
        "    population[i] = population[i][:j] + str(1-int(population[i][j])) + population[i][j+1:]\n",
        "  \n",
        "  return population"
      ],
      "metadata": {
        "id": "uCyA6Ou-_UI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# s = generate_population(4,10)\n",
        "# print(s)\n",
        "# p = mutation(s)\n",
        "# print('\\n',p)"
      ],
      "metadata": {
        "id": "IJ5tJ1AXBpB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create ANN Network"
      ],
      "metadata": {
        "id": "WndLf2-J_CCm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def define_af(af):\n",
        "\n",
        "  if af == 1:\n",
        "    return tanh, tanh_prime\n",
        "  else:\n",
        "    return sigmoid, sigmoid_prime"
      ],
      "metadata": {
        "id": "sC_9Sw-4FeBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_ann_network(X_train, y_train, neuron_0, neuron_1, neuron_2, neuron_3, af1, af2, af3, af4):\n",
        "\n",
        "  af1, af1_prime = define_af(af1)\n",
        "  af2, af2_prime = define_af(af2)\n",
        "  af3, af3_prime = define_af(af3)\n",
        "  af4, af4_prime = define_af(af4)\n",
        "  \n",
        "  net = Network()\n",
        "\n",
        "  # input layer\n",
        "  neuron_input = X_train.shape[2]\n",
        "  net.add(FCLayer(neuron_input, neuron_0))\n",
        "  net.add(ActivationLayer(af1, af1_prime))\n",
        "\n",
        "  # hidden layer 1\n",
        "  net.add(FCLayer(neuron_0, neuron_1))\n",
        "  net.add(ActivationLayer(af2, af2_prime))\n",
        "\n",
        "  # hidden layer 2\n",
        "  net.add(FCLayer(neuron_1, neuron_2))\n",
        "  net.add(ActivationLayer(af3, af3_prime))\n",
        "\n",
        "  # hidden layer 3\n",
        "  net.add(FCLayer(neuron_2, neuron_3))\n",
        "  net.add(ActivationLayer(af4, af4_prime))\n",
        "\n",
        "  # output layer\n",
        "  neuron_output = y_train.shape[2]\n",
        "  net.add(FCLayer(neuron_3, neuron_output))\n",
        "  net.add(ActivationLayer(softmax, softmax_prime))\n",
        "\n",
        "  # loss\n",
        "  net.use(cross_entropy, cross_entropy_prime)\n",
        "\n",
        "  return net"
      ],
      "metadata": {
        "id": "LZEQPp1uD473"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make Predictions"
      ],
      "metadata": {
        "id": "2qSY3CyM_HU6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.metrics import accuracy_score\n",
        "\n",
        "def predict(X_test, net):\n",
        "\n",
        "  out = net.predict(X_test)\n",
        "  pred = np.array(out)\n",
        "\n",
        "  pred = pred.reshape(pred.shape[0], pred.shape[2])\n",
        "  # pred_ratings = np.argmax(pred, axis=1)+1\n",
        "\n",
        "  return pred"
      ],
      "metadata": {
        "id": "Ud8N9CJlMTHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Define Range for Learning rate and Number of Epochs"
      ],
      "metadata": {
        "id": "NSUnSkfRStgq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LR = [0.1, 0.15, 0.2, 0.3, 0.5, 0.8, 0.9, 1]\n",
        "EPOCHS = [5, 6, 8, 9, 10, 13, 15, 20]"
      ],
      "metadata": {
        "id": "FPR3UYqcSQXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate Error for each topology"
      ],
      "metadata": {
        "id": "FsStMpi1JMC5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_error(X_train, y_train, X_test, y_test, topology_structure):\n",
        "\n",
        "  # return Mean Squared error after implementing ANN\n",
        "  # print(topology_structure)\n",
        "  n_0 = int(topology_structure[:5], 2)\n",
        "  n_1 = int(topology_structure[5:10], 2)\n",
        "  n_2 = int(topology_structure[10:15], 2)\n",
        "  n_3 = int(topology_structure[15:20], 2)\n",
        "\n",
        "  af1 = int(topology_structure[20])\n",
        "  af2 = int(topology_structure[21])\n",
        "  af3 = int(topology_structure[22])\n",
        "  af4 = int(topology_structure[23])\n",
        "\n",
        "  lr = LR[int(topology_structure[24:27], 2)]\n",
        "  epochs = EPOCHS[int(topology_structure[27:30], 2)]\n",
        "\n",
        "  net = create_ann_network(X_train, y_train, n_0, n_1, n_2, n_3, af1, af2, af3, af4)\n",
        "\n",
        "  # train\n",
        "  net.fit(X_train, y_train, epochs, lr)\n",
        "\n",
        "  # predict\n",
        "  pred = predict(X_test, net)\n",
        "\n",
        "  # calculate cross entropy loss\n",
        "  loss = cross_entropy(y_test, pred)\n",
        "  return loss"
      ],
      "metadata": {
        "id": "ipMkcYOyJGEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate Fitness values for all chromosomes/topologies"
      ],
      "metadata": {
        "id": "qguemvY2JGbk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_fitness(X_train, y_train, X_test, y_test, population):\n",
        "\n",
        "  fitness_values = []\n",
        "  for chromosome in population:\n",
        "\n",
        "    # calculate error for particular topology\n",
        "    fitness_values.append(1/calculate_error(X_train, y_train, X_test, y_test, chromosome))\n",
        "  \n",
        "  return fitness_values"
      ],
      "metadata": {
        "id": "TUCx4v-MGFjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Selection"
      ],
      "metadata": {
        "id": "N66ThmmaMKeO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def selection(population, fitness_values):\n",
        "\n",
        "  # Roulette Wheel Selection\n",
        "  # Total fitness value of population\n",
        "  population_fitness = sum(fitness_values)\n",
        "  \n",
        "  fitness_values = [val/population_fitness for val in fitness_values]\n",
        "\n",
        "  # chromosome with high fitness value has more chances of selection in mating pool\n",
        "  population = np.random.choice(a = population, p = fitness_values, size = len(population))\n",
        "\n",
        "  return population"
      ],
      "metadata": {
        "id": "BtmQJlhwKAgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# p=generate_population(10,4)\n",
        "# print(p)\n",
        "# f=calculate_fitness(p)\n",
        "# p2=selection(p,f)\n",
        "# print(p2)\n",
        "\n",
        "# Output\n",
        "\n",
        "# ['0100', '0110', '0111', '0111', '0001', '1110', '0111', '0111', '0000', '0001']\n",
        "# [0.03740263543025862, 0.1444143799475979, 0.27212793943351327, 0.10787501429705755, 0.13738433714272053, 0.03855198616610927, 0.0952309097131657, 0.08759249823259811, 0.04064053578467348, 0.038779763852305756]\n",
        "# ['0111' '0111' '0111' '0111' '0110' '0111' '0111' '0001' '0111' '0000']"
      ],
      "metadata": {
        "id": "73KidTrTXqkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Genetic Algorithm"
      ],
      "metadata": {
        "id": "2AGnzcRshIss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "######### give default values\n",
        "def genetic_algorithm(X_train, y_train, X_test, y_test, pop_size, ch_length, generations, mutation_prob):\n",
        "\n",
        "  # Step 1: Create population\n",
        "  population = generate_population(pop_size, ch_length)\n",
        "  for i in range(generations):\n",
        "\n",
        "      # Step 2: Calculate fitness values for each chromosome\n",
        "      fitness_values = calculate_fitness(X_train, y_train, X_test, y_test, population)\n",
        "\n",
        "      # Step 3: Selection\n",
        "      population = selection(population, fitness_values)\n",
        "\n",
        "      # Step 4: Crossover\n",
        "      for i in range(0, len(population), 2):\n",
        "        population[i], population[i+1] = single_point_crossover(population[i], population[i+1])\n",
        "\n",
        "      # Step 5: Mutation\n",
        "      population = mutation(population, mutation_prob)\n",
        "  fitness_values = calculate_fitness(X_train, y_train, X_test, y_test, population)\n",
        "\n",
        "  # population sorted according to fitness values in ascending order\n",
        "  sorted_fitness_idx = np.array(fitness_values).argsort()\n",
        "  population = population[sorted_fitness_idx[::-1]]\n",
        "  \n",
        "  return population"
      ],
      "metadata": {
        "id": "netcR_f-HxIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chromosome Binary Encoding\n",
        "\n",
        "##### 5 bits each are used for Number of Neurons in 4 hidden layers\n",
        "\n",
        "##### 4 bits each are used for Activation Function at each layer  \n",
        "\n",
        "##### 3 bits for Learning Rate\n",
        "\n",
        "##### 3 bits for Number of Epochs"
      ],
      "metadata": {
        "id": "Bzs_FtB-G7wj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# genetic_algorithm(10, 4, 1, 0.2)"
      ],
      "metadata": {
        "id": "N7WLRdoNI_PK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Defining Genetic Algorithm Parameters"
      ],
      "metadata": {
        "id": "ypqK5NfVhFnJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "population_size = 10\n",
        "chromosome_length = 30\n",
        "generations = 5\n",
        "mutation_prob = 0.2"
      ],
      "metadata": {
        "id": "EWiiZ4M9gkfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Running the Genetic Algorithm"
      ],
      "metadata": {
        "id": "5vsPPye-TtnD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_population = genetic_algorithm(X_train, y_train, X_test, y_test, population_size, chromosome_length, generations, mutation_prob)"
      ],
      "metadata": {
        "id": "52UklvTigpoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Best Topology"
      ],
      "metadata": {
        "id": "qvoCEJteT0Sp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimized_topology = final_population[0]"
      ],
      "metadata": {
        "id": "kfaUjWkmH5mV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Display Optimized Topology Structure"
      ],
      "metadata": {
        "id": "-hc31r_WTjAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display_topology(optimized_topology):\n",
        "  n_0 = int(optimized_topology[:5], 2)\n",
        "  n_1 = int(optimized_topology[5:10], 2)\n",
        "  n_2 = int(optimized_topology[10:15], 2)\n",
        "  n_3 = int(optimized_topology[15:20], 2)\n",
        "\n",
        "  af1 = int(optimized_topology[20])\n",
        "  af2 = int(optimized_topology[21])\n",
        "  af3 = int(optimized_topology[22])\n",
        "  af4 = int(optimized_topology[23])\n",
        "\n",
        "  lr = LR[int(optimized_topology[24:27], 2)]\n",
        "  epochs = EPOCHS[int(optimized_topology[27:30], 2)]\n",
        "\n",
        "  print('Number of neurons in input layer: ', X_train.shape[2])\n",
        "  print('Number of neurons in first hidden layer: ', n_0)\n",
        "  print('Number of neurons in second hidden layer: ', n_1)\n",
        "  print('Number of neurons in third hidden layer: ', n_2)\n",
        "  print('Number of neurons in output layer: ', n_3)\n",
        "  print('\\n')\n",
        "  print('Activation Function in input layer: ', define_af(af1))\n",
        "  print('Activation Function in first hidden layer: ', define_af(af2))\n",
        "  print('Activation Function in second layer: ', define_af(af3))\n",
        "  print('Activation Function in third layer: ', define_af(af4))\n",
        "  print('Activation Function in output layer: Softmax')\n",
        "  print('\\n')\n",
        "  print('Learning Rate:  ', lr)\n",
        "  print('Number of Epochs:  ', epochs)"
      ],
      "metadata": {
        "id": "nkYHf436eTL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_topology(optimized_topology)"
      ],
      "metadata": {
        "id": "ay-tUkYUe5vr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training the dataset on topology obtained from Genetic Algorithm"
      ],
      "metadata": {
        "id": "n0h0DmCWT5mv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model(X_train, y_train, X_test, y_test, topology_structure):\n",
        "\n",
        "  n_0 = int(topology_structure[:5], 2)\n",
        "  n_1 = int(topology_structure[5:10], 2)\n",
        "  n_2 = int(topology_structure[10:15], 2)\n",
        "  n_3 = int(topology_structure[15:20], 2)\n",
        "\n",
        "  af1 = int(topology_structure[20])\n",
        "  af2 = int(topology_structure[21])\n",
        "  af3 = int(topology_structure[22])\n",
        "  af4 = int(topology_structure[23])\n",
        "\n",
        "  lr = LR[int(topology_structure[24:27], 2)]\n",
        "  epochs = EPOCHS[int(topology_structure[27:30], 2)]\n",
        "\n",
        "  net = create_ann_network(X_train, y_train, n_0, n_1, n_2, n_3, af1, af2, af3, af4)\n",
        "\n",
        "  # train\n",
        "  net.fit(X_train, y_train, epochs, lr)\n",
        "\n",
        "  # predict\n",
        "  pred = predict(X_test, net)\n",
        "  pred = pred.reshape(pred.shape[0], pred.shape[1])\n",
        "  # rating  = max prob out of 5\n",
        "  pred_ratings = np.argmax(pred, axis=1)+1\n",
        "\n",
        "  # calculate cross entropy loss\n",
        "  loss = cross_entropy(y_test, pred)\n",
        "  accuracy = accuracy_score(y_true, pred_ratings)\n",
        "  return pred_ratings"
      ],
      "metadata": {
        "id": "JcVpj_fWrQTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_ratings = model(X_train, y_train, X_test, y_test, optimized_topology)\n",
        "pred_ratings"
      ],
      "metadata": {
        "id": "PoP_PfIlcyjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_true = pd.Series(y_true, name='y_true')\n",
        "Y_pred = pd.Series(pred_ratings, name='y_pred')"
      ],
      "metadata": {
        "id": "PAdadQDB2Hs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cmp = pd.concat([Y_true, Y_pred], axis=1)\n",
        "cmp = cmp.sample(n=30, ignore_index=True)\n",
        "cmp.columns=['y_true', 'y_pred']\n",
        "cmp.head(30)"
      ],
      "metadata": {
        "id": "_g1Ieabj5HGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy = accuracy_score(Y_true, Y_pred)\n",
        "print(\"Accuracy for the model is: \", accuracy)"
      ],
      "metadata": {
        "id": "DNTBdsYQ2mo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = np.arange(y_true.shape[0])"
      ],
      "metadata": {
        "id": "IN55PC00YOfT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct_predictions = 0\n",
        "for i in range(len(idx)):\n",
        "  if Y_pred[i]==Y_true[i]:\n",
        "    correct_predictions += 1\n",
        "print(correct_predictions)\n",
        "incorrect_predictions = len(y_true)-correct_predictions\n",
        "print(incorrect_predictions)"
      ],
      "metadata": {
        "id": "xbbP1ywX8PZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,6))\n",
        "sns.barplot(['Correct Predictions', 'Incorrect Predictions'], [correct_predictions, incorrect_predictions])\n",
        "plt.title('Count of Correct and Incorrect Predictions', fontsize=15)\n",
        "plt.xlabel('Predictions', fontsize=12)\n",
        "plt.ylabel('Count', fontsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GSltmEzy7yXc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}